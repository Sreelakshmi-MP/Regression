{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gene_Expression_Data-Logistic_Regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7Brld2xCEY6i"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn import linear_model, preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls',names=None,index_col=None)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "ZyNABTgoEm2H",
        "outputId": "0d6052bf-4612-4b1b-9f6c-e47010503ec5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MouseID</th>\n",
              "      <th>DYRK1A_N</th>\n",
              "      <th>ITSN1_N</th>\n",
              "      <th>BDNF_N</th>\n",
              "      <th>NR1_N</th>\n",
              "      <th>NR2A_N</th>\n",
              "      <th>pAKT_N</th>\n",
              "      <th>pBRAF_N</th>\n",
              "      <th>pCAMKII_N</th>\n",
              "      <th>pCREB_N</th>\n",
              "      <th>pELK_N</th>\n",
              "      <th>pERK_N</th>\n",
              "      <th>pJNK_N</th>\n",
              "      <th>PKCA_N</th>\n",
              "      <th>pMEK_N</th>\n",
              "      <th>pNR1_N</th>\n",
              "      <th>pNR2A_N</th>\n",
              "      <th>pNR2B_N</th>\n",
              "      <th>pPKCAB_N</th>\n",
              "      <th>pRSK_N</th>\n",
              "      <th>AKT_N</th>\n",
              "      <th>BRAF_N</th>\n",
              "      <th>CAMKII_N</th>\n",
              "      <th>CREB_N</th>\n",
              "      <th>ELK_N</th>\n",
              "      <th>ERK_N</th>\n",
              "      <th>GSK3B_N</th>\n",
              "      <th>JNK_N</th>\n",
              "      <th>MEK_N</th>\n",
              "      <th>TRKA_N</th>\n",
              "      <th>RSK_N</th>\n",
              "      <th>APP_N</th>\n",
              "      <th>Bcatenin_N</th>\n",
              "      <th>SOD1_N</th>\n",
              "      <th>MTOR_N</th>\n",
              "      <th>P38_N</th>\n",
              "      <th>pMTOR_N</th>\n",
              "      <th>DSCR1_N</th>\n",
              "      <th>AMPKA_N</th>\n",
              "      <th>NR2B_N</th>\n",
              "      <th>...</th>\n",
              "      <th>TIAM1_N</th>\n",
              "      <th>pP70S6_N</th>\n",
              "      <th>NUMB_N</th>\n",
              "      <th>P70S6_N</th>\n",
              "      <th>pGSK3B_N</th>\n",
              "      <th>pPKCG_N</th>\n",
              "      <th>CDK5_N</th>\n",
              "      <th>S6_N</th>\n",
              "      <th>ADARB1_N</th>\n",
              "      <th>AcetylH3K9_N</th>\n",
              "      <th>RRP1_N</th>\n",
              "      <th>BAX_N</th>\n",
              "      <th>ARC_N</th>\n",
              "      <th>ERBB4_N</th>\n",
              "      <th>nNOS_N</th>\n",
              "      <th>Tau_N</th>\n",
              "      <th>GFAP_N</th>\n",
              "      <th>GluR3_N</th>\n",
              "      <th>GluR4_N</th>\n",
              "      <th>IL1B_N</th>\n",
              "      <th>P3525_N</th>\n",
              "      <th>pCASP9_N</th>\n",
              "      <th>PSD95_N</th>\n",
              "      <th>SNCA_N</th>\n",
              "      <th>Ubiquitin_N</th>\n",
              "      <th>pGSK3B_Tyr216_N</th>\n",
              "      <th>SHH_N</th>\n",
              "      <th>BAD_N</th>\n",
              "      <th>BCL2_N</th>\n",
              "      <th>pS6_N</th>\n",
              "      <th>pCFOS_N</th>\n",
              "      <th>SYP_N</th>\n",
              "      <th>H3AcK18_N</th>\n",
              "      <th>EGR1_N</th>\n",
              "      <th>H3MeK4_N</th>\n",
              "      <th>CaNA_N</th>\n",
              "      <th>Genotype</th>\n",
              "      <th>Treatment</th>\n",
              "      <th>Behavior</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>309_1</td>\n",
              "      <td>0.503644</td>\n",
              "      <td>0.747193</td>\n",
              "      <td>0.430175</td>\n",
              "      <td>2.816329</td>\n",
              "      <td>5.990152</td>\n",
              "      <td>0.218830</td>\n",
              "      <td>0.177565</td>\n",
              "      <td>2.373744</td>\n",
              "      <td>0.232224</td>\n",
              "      <td>1.750936</td>\n",
              "      <td>0.687906</td>\n",
              "      <td>0.306382</td>\n",
              "      <td>0.402698</td>\n",
              "      <td>0.296927</td>\n",
              "      <td>1.022060</td>\n",
              "      <td>0.605673</td>\n",
              "      <td>1.877684</td>\n",
              "      <td>2.308745</td>\n",
              "      <td>0.441599</td>\n",
              "      <td>0.859366</td>\n",
              "      <td>0.416289</td>\n",
              "      <td>0.369608</td>\n",
              "      <td>0.178944</td>\n",
              "      <td>1.866358</td>\n",
              "      <td>3.685247</td>\n",
              "      <td>1.537227</td>\n",
              "      <td>0.264526</td>\n",
              "      <td>0.319677</td>\n",
              "      <td>0.813866</td>\n",
              "      <td>0.165846</td>\n",
              "      <td>0.453910</td>\n",
              "      <td>3.037621</td>\n",
              "      <td>0.369510</td>\n",
              "      <td>0.458539</td>\n",
              "      <td>0.335336</td>\n",
              "      <td>0.825192</td>\n",
              "      <td>0.576916</td>\n",
              "      <td>0.448099</td>\n",
              "      <td>0.586271</td>\n",
              "      <td>...</td>\n",
              "      <td>0.482864</td>\n",
              "      <td>0.294170</td>\n",
              "      <td>0.182150</td>\n",
              "      <td>0.842725</td>\n",
              "      <td>0.192608</td>\n",
              "      <td>1.443091</td>\n",
              "      <td>0.294700</td>\n",
              "      <td>0.354605</td>\n",
              "      <td>1.339070</td>\n",
              "      <td>0.170119</td>\n",
              "      <td>0.159102</td>\n",
              "      <td>0.188852</td>\n",
              "      <td>0.106305</td>\n",
              "      <td>0.144989</td>\n",
              "      <td>0.176668</td>\n",
              "      <td>0.125190</td>\n",
              "      <td>0.115291</td>\n",
              "      <td>0.228043</td>\n",
              "      <td>0.142756</td>\n",
              "      <td>0.430957</td>\n",
              "      <td>0.247538</td>\n",
              "      <td>1.603310</td>\n",
              "      <td>2.014875</td>\n",
              "      <td>0.108234</td>\n",
              "      <td>1.044979</td>\n",
              "      <td>0.831557</td>\n",
              "      <td>0.188852</td>\n",
              "      <td>0.122652</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.106305</td>\n",
              "      <td>0.108336</td>\n",
              "      <td>0.427099</td>\n",
              "      <td>0.114783</td>\n",
              "      <td>0.131790</td>\n",
              "      <td>0.128186</td>\n",
              "      <td>1.675652</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>309_2</td>\n",
              "      <td>0.514617</td>\n",
              "      <td>0.689064</td>\n",
              "      <td>0.411770</td>\n",
              "      <td>2.789514</td>\n",
              "      <td>5.685038</td>\n",
              "      <td>0.211636</td>\n",
              "      <td>0.172817</td>\n",
              "      <td>2.292150</td>\n",
              "      <td>0.226972</td>\n",
              "      <td>1.596377</td>\n",
              "      <td>0.695006</td>\n",
              "      <td>0.299051</td>\n",
              "      <td>0.385987</td>\n",
              "      <td>0.281319</td>\n",
              "      <td>0.956676</td>\n",
              "      <td>0.587559</td>\n",
              "      <td>1.725774</td>\n",
              "      <td>2.043037</td>\n",
              "      <td>0.445222</td>\n",
              "      <td>0.834659</td>\n",
              "      <td>0.400364</td>\n",
              "      <td>0.356178</td>\n",
              "      <td>0.173680</td>\n",
              "      <td>1.761047</td>\n",
              "      <td>3.485287</td>\n",
              "      <td>1.509249</td>\n",
              "      <td>0.255727</td>\n",
              "      <td>0.304419</td>\n",
              "      <td>0.780504</td>\n",
              "      <td>0.157194</td>\n",
              "      <td>0.430940</td>\n",
              "      <td>2.921882</td>\n",
              "      <td>0.342279</td>\n",
              "      <td>0.423560</td>\n",
              "      <td>0.324835</td>\n",
              "      <td>0.761718</td>\n",
              "      <td>0.545097</td>\n",
              "      <td>0.420876</td>\n",
              "      <td>0.545097</td>\n",
              "      <td>...</td>\n",
              "      <td>0.454519</td>\n",
              "      <td>0.276431</td>\n",
              "      <td>0.182086</td>\n",
              "      <td>0.847615</td>\n",
              "      <td>0.194815</td>\n",
              "      <td>1.439460</td>\n",
              "      <td>0.294060</td>\n",
              "      <td>0.354548</td>\n",
              "      <td>1.306323</td>\n",
              "      <td>0.171427</td>\n",
              "      <td>0.158129</td>\n",
              "      <td>0.184570</td>\n",
              "      <td>0.106592</td>\n",
              "      <td>0.150471</td>\n",
              "      <td>0.178309</td>\n",
              "      <td>0.134275</td>\n",
              "      <td>0.118235</td>\n",
              "      <td>0.238073</td>\n",
              "      <td>0.142037</td>\n",
              "      <td>0.457156</td>\n",
              "      <td>0.257632</td>\n",
              "      <td>1.671738</td>\n",
              "      <td>2.004605</td>\n",
              "      <td>0.109749</td>\n",
              "      <td>1.009883</td>\n",
              "      <td>0.849270</td>\n",
              "      <td>0.200404</td>\n",
              "      <td>0.116682</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.106592</td>\n",
              "      <td>0.104315</td>\n",
              "      <td>0.441581</td>\n",
              "      <td>0.111974</td>\n",
              "      <td>0.135103</td>\n",
              "      <td>0.131119</td>\n",
              "      <td>1.743610</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>309_3</td>\n",
              "      <td>0.509183</td>\n",
              "      <td>0.730247</td>\n",
              "      <td>0.418309</td>\n",
              "      <td>2.687201</td>\n",
              "      <td>5.622059</td>\n",
              "      <td>0.209011</td>\n",
              "      <td>0.175722</td>\n",
              "      <td>2.283337</td>\n",
              "      <td>0.230247</td>\n",
              "      <td>1.561316</td>\n",
              "      <td>0.677348</td>\n",
              "      <td>0.291276</td>\n",
              "      <td>0.381002</td>\n",
              "      <td>0.281710</td>\n",
              "      <td>1.003635</td>\n",
              "      <td>0.602449</td>\n",
              "      <td>1.731873</td>\n",
              "      <td>2.017984</td>\n",
              "      <td>0.467668</td>\n",
              "      <td>0.814329</td>\n",
              "      <td>0.399847</td>\n",
              "      <td>0.368089</td>\n",
              "      <td>0.173905</td>\n",
              "      <td>1.765544</td>\n",
              "      <td>3.571456</td>\n",
              "      <td>1.501244</td>\n",
              "      <td>0.259614</td>\n",
              "      <td>0.311747</td>\n",
              "      <td>0.785154</td>\n",
              "      <td>0.160895</td>\n",
              "      <td>0.423187</td>\n",
              "      <td>2.944136</td>\n",
              "      <td>0.343696</td>\n",
              "      <td>0.425005</td>\n",
              "      <td>0.324852</td>\n",
              "      <td>0.757031</td>\n",
              "      <td>0.543620</td>\n",
              "      <td>0.404630</td>\n",
              "      <td>0.552994</td>\n",
              "      <td>...</td>\n",
              "      <td>0.447197</td>\n",
              "      <td>0.256648</td>\n",
              "      <td>0.184388</td>\n",
              "      <td>0.856166</td>\n",
              "      <td>0.200737</td>\n",
              "      <td>1.524364</td>\n",
              "      <td>0.301881</td>\n",
              "      <td>0.386087</td>\n",
              "      <td>1.279600</td>\n",
              "      <td>0.185456</td>\n",
              "      <td>0.148696</td>\n",
              "      <td>0.190532</td>\n",
              "      <td>0.108303</td>\n",
              "      <td>0.145330</td>\n",
              "      <td>0.176213</td>\n",
              "      <td>0.132560</td>\n",
              "      <td>0.117760</td>\n",
              "      <td>0.244817</td>\n",
              "      <td>0.142445</td>\n",
              "      <td>0.510472</td>\n",
              "      <td>0.255343</td>\n",
              "      <td>1.663550</td>\n",
              "      <td>2.016831</td>\n",
              "      <td>0.108196</td>\n",
              "      <td>0.996848</td>\n",
              "      <td>0.846709</td>\n",
              "      <td>0.193685</td>\n",
              "      <td>0.118508</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.108303</td>\n",
              "      <td>0.106219</td>\n",
              "      <td>0.435777</td>\n",
              "      <td>0.111883</td>\n",
              "      <td>0.133362</td>\n",
              "      <td>0.127431</td>\n",
              "      <td>1.926427</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>309_4</td>\n",
              "      <td>0.442107</td>\n",
              "      <td>0.617076</td>\n",
              "      <td>0.358626</td>\n",
              "      <td>2.466947</td>\n",
              "      <td>4.979503</td>\n",
              "      <td>0.222886</td>\n",
              "      <td>0.176463</td>\n",
              "      <td>2.152301</td>\n",
              "      <td>0.207004</td>\n",
              "      <td>1.595086</td>\n",
              "      <td>0.583277</td>\n",
              "      <td>0.296729</td>\n",
              "      <td>0.377087</td>\n",
              "      <td>0.313832</td>\n",
              "      <td>0.875390</td>\n",
              "      <td>0.520293</td>\n",
              "      <td>1.566852</td>\n",
              "      <td>2.132754</td>\n",
              "      <td>0.477671</td>\n",
              "      <td>0.727705</td>\n",
              "      <td>0.385639</td>\n",
              "      <td>0.362970</td>\n",
              "      <td>0.179449</td>\n",
              "      <td>1.286277</td>\n",
              "      <td>2.970137</td>\n",
              "      <td>1.419710</td>\n",
              "      <td>0.259536</td>\n",
              "      <td>0.279218</td>\n",
              "      <td>0.734492</td>\n",
              "      <td>0.162210</td>\n",
              "      <td>0.410615</td>\n",
              "      <td>2.500204</td>\n",
              "      <td>0.344509</td>\n",
              "      <td>0.429211</td>\n",
              "      <td>0.330121</td>\n",
              "      <td>0.746980</td>\n",
              "      <td>0.546763</td>\n",
              "      <td>0.386860</td>\n",
              "      <td>0.547849</td>\n",
              "      <td>...</td>\n",
              "      <td>0.442650</td>\n",
              "      <td>0.398534</td>\n",
              "      <td>0.161768</td>\n",
              "      <td>0.760234</td>\n",
              "      <td>0.184169</td>\n",
              "      <td>1.612382</td>\n",
              "      <td>0.296382</td>\n",
              "      <td>0.290680</td>\n",
              "      <td>1.198765</td>\n",
              "      <td>0.159799</td>\n",
              "      <td>0.166112</td>\n",
              "      <td>0.185323</td>\n",
              "      <td>0.103184</td>\n",
              "      <td>0.140656</td>\n",
              "      <td>0.163804</td>\n",
              "      <td>0.123210</td>\n",
              "      <td>0.117439</td>\n",
              "      <td>0.234947</td>\n",
              "      <td>0.145068</td>\n",
              "      <td>0.430996</td>\n",
              "      <td>0.251103</td>\n",
              "      <td>1.484624</td>\n",
              "      <td>1.957233</td>\n",
              "      <td>0.119883</td>\n",
              "      <td>0.990225</td>\n",
              "      <td>0.833277</td>\n",
              "      <td>0.192112</td>\n",
              "      <td>0.132781</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.103184</td>\n",
              "      <td>0.111262</td>\n",
              "      <td>0.391691</td>\n",
              "      <td>0.130405</td>\n",
              "      <td>0.147444</td>\n",
              "      <td>0.146901</td>\n",
              "      <td>1.700563</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>309_5</td>\n",
              "      <td>0.434940</td>\n",
              "      <td>0.617430</td>\n",
              "      <td>0.358802</td>\n",
              "      <td>2.365785</td>\n",
              "      <td>4.718679</td>\n",
              "      <td>0.213106</td>\n",
              "      <td>0.173627</td>\n",
              "      <td>2.134014</td>\n",
              "      <td>0.192158</td>\n",
              "      <td>1.504230</td>\n",
              "      <td>0.550960</td>\n",
              "      <td>0.286961</td>\n",
              "      <td>0.363502</td>\n",
              "      <td>0.277964</td>\n",
              "      <td>0.864912</td>\n",
              "      <td>0.507990</td>\n",
              "      <td>1.480059</td>\n",
              "      <td>2.013697</td>\n",
              "      <td>0.483416</td>\n",
              "      <td>0.687794</td>\n",
              "      <td>0.367531</td>\n",
              "      <td>0.355311</td>\n",
              "      <td>0.174836</td>\n",
              "      <td>1.324695</td>\n",
              "      <td>2.896334</td>\n",
              "      <td>1.359876</td>\n",
              "      <td>0.250705</td>\n",
              "      <td>0.273667</td>\n",
              "      <td>0.702699</td>\n",
              "      <td>0.154827</td>\n",
              "      <td>0.398550</td>\n",
              "      <td>2.456560</td>\n",
              "      <td>0.329126</td>\n",
              "      <td>0.408755</td>\n",
              "      <td>0.313415</td>\n",
              "      <td>0.691956</td>\n",
              "      <td>0.536860</td>\n",
              "      <td>0.360816</td>\n",
              "      <td>0.512824</td>\n",
              "      <td>...</td>\n",
              "      <td>0.419095</td>\n",
              "      <td>0.393447</td>\n",
              "      <td>0.160200</td>\n",
              "      <td>0.768113</td>\n",
              "      <td>0.185718</td>\n",
              "      <td>1.645807</td>\n",
              "      <td>0.296829</td>\n",
              "      <td>0.309345</td>\n",
              "      <td>1.206995</td>\n",
              "      <td>0.164650</td>\n",
              "      <td>0.160687</td>\n",
              "      <td>0.188221</td>\n",
              "      <td>0.104784</td>\n",
              "      <td>0.141983</td>\n",
              "      <td>0.167710</td>\n",
              "      <td>0.136838</td>\n",
              "      <td>0.116048</td>\n",
              "      <td>0.255528</td>\n",
              "      <td>0.140871</td>\n",
              "      <td>0.481227</td>\n",
              "      <td>0.251773</td>\n",
              "      <td>1.534835</td>\n",
              "      <td>2.009109</td>\n",
              "      <td>0.119524</td>\n",
              "      <td>0.997775</td>\n",
              "      <td>0.878668</td>\n",
              "      <td>0.205604</td>\n",
              "      <td>0.129954</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.104784</td>\n",
              "      <td>0.110694</td>\n",
              "      <td>0.434154</td>\n",
              "      <td>0.118481</td>\n",
              "      <td>0.140314</td>\n",
              "      <td>0.148380</td>\n",
              "      <td>1.839730</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 82 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  MouseID  DYRK1A_N   ITSN1_N    BDNF_N  ...  Genotype  Treatment  Behavior   class\n",
              "0   309_1  0.503644  0.747193  0.430175  ...   Control  Memantine       C/S  c-CS-m\n",
              "1   309_2  0.514617  0.689064  0.411770  ...   Control  Memantine       C/S  c-CS-m\n",
              "2   309_3  0.509183  0.730247  0.418309  ...   Control  Memantine       C/S  c-CS-m\n",
              "3   309_4  0.442107  0.617076  0.358626  ...   Control  Memantine       C/S  c-CS-m\n",
              "4   309_5  0.434940  0.617430  0.358802  ...   Control  Memantine       C/S  c-CS-m\n",
              "\n",
              "[5 rows x 82 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.where(pd.notnull(df), df.mean(), axis='columns')"
      ],
      "metadata": {
        "id": "uL0q1klFEm5r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z,y = np.unique(df1['Genotype'].values, return_inverse=True)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMZNHP9sEm8s",
        "outputId": "0c59c5c4-d01c-4bea-fd8c-4868d253e153"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df1.iloc[:,1:78]\n",
        "Xs = preprocessing.scale(X)\n",
        "\n",
        "logreg = linear_model.LogisticRegression(C=1)\n",
        "logreg.fit(Xs, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4zUNzwvEm_0",
        "outputId": "c2e82a79-372a-47e7-eed6-f721295c194c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = logreg.predict(Xs)\n",
        "acc = np.mean(yhat == y)\n",
        "print(\"Accuracy on training data = %f\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soZYVvWrEnCi",
        "outputId": "28e79c8a-948c-4ced-db24-2c65a6cc3456"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training data = 0.985185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'feature': X.columns, 'slope': np.squeeze(logreg.coef_)}\n",
        "dfslope = pd.DataFrame(data=data)\n",
        "dfslope"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "O1h71dMQEnFJ",
        "outputId": "be135f24-532f-4ecd-ab7a-dee422c7fcbc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>slope</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DYRK1A_N</td>\n",
              "      <td>0.257210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ITSN1_N</td>\n",
              "      <td>3.088529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BDNF_N</td>\n",
              "      <td>0.202844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NR1_N</td>\n",
              "      <td>-0.785338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NR2A_N</td>\n",
              "      <td>-0.323751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>SYP_N</td>\n",
              "      <td>-1.255127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>H3AcK18_N</td>\n",
              "      <td>-0.346074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>EGR1_N</td>\n",
              "      <td>0.174129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>H3MeK4_N</td>\n",
              "      <td>-0.210022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>CaNA_N</td>\n",
              "      <td>0.990758</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>77 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      feature     slope\n",
              "0    DYRK1A_N  0.257210\n",
              "1     ITSN1_N  3.088529\n",
              "2      BDNF_N  0.202844\n",
              "3       NR1_N -0.785338\n",
              "4      NR2A_N -0.323751\n",
              "..        ...       ...\n",
              "72      SYP_N -1.255127\n",
              "73  H3AcK18_N -0.346074\n",
              "74     EGR1_N  0.174129\n",
              "75   H3MeK4_N -0.210022\n",
              "76     CaNA_N  0.990758\n",
              "\n",
              "[77 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.stem(dfslope.index,dfslope['slope'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "B_3s_w92EnHw",
        "outputId": "2bd1dca0-2889-4466-e411-768ddff0b407"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: In Matplotlib 3.3 individual lines on a stem plot will be added as a LineCollection instead of individual lines. This significantly improves the performance of a stem plot. To remove this warning and switch to the new behaviour, set the \"use_line_collection\" keyword argument to True.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<StemContainer object of 3 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Isel = (-dfslope['slope']).argsort()[:2]\n",
        "print(\"The gene with the largest w is %s\"% dfslope.feature[Isel[0]])\n",
        "print(\"The gene with the second largest w is %s\"% dfslope.feature[Isel[1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq92Xa8gEnLQ",
        "outputId": "ebdf16ad-96fd-4eb7-b0a2-95ec0f272c53"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The gene with the largest w is ITSN1_N\n",
            "The gene with the second largest w is APP_N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import KFold\n",
        "import  sklearn.model_selection\n",
        "\n",
        "nfold = 10\n",
        "prec = []\n",
        "rec = []\n",
        "f1 = []\n",
        "acc = []\n",
        "\n",
        "kf = sklearn.model_selection.KFold(n_splits=nfold,shuffle=True)\n",
        "\n",
        "for train, test in kf.split(Xs): \n",
        "       \n",
        "    # Get training and test data\n",
        "    Xtr = Xs[train,:]\n",
        "    ytr = y[train]\n",
        "    Xts = Xs[test,:]\n",
        "    yts = y[test]\n",
        "    \n",
        "    # Fit a model\n",
        "    logreg.fit(Xtr, ytr)\n",
        "    yhat = logreg.predict(Xts)\n",
        "    \n",
        "    # Measure performance\n",
        "    preci,reci,f1i,_= precision_recall_fscore_support(yts,yhat,average='binary') \n",
        "    prec.append(preci)\n",
        "    rec.append(reci)\n",
        "    f1.append(f1i)\n",
        "    acci = np.mean(yhat == yts)\n",
        "    acc.append(acci)\n",
        "\n",
        "# Take average values of the metrics\n",
        "precm = np.mean(prec)\n",
        "recm = np.mean(rec)\n",
        "f1m = np.mean(f1)\n",
        "accm= np.mean(acc)\n",
        "\n",
        "# Compute the standard errors\n",
        "prec_se = np.std(prec)/np.sqrt(nfold-1)\n",
        "rec_se = np.std(rec)/np.sqrt(nfold-1)\n",
        "f1_se = np.std(f1)/np.sqrt(nfold-1)\n",
        "acc_se = np.std(acc)/np.sqrt(nfold-1)\n",
        "\n",
        "print('Precision = {0:.4f}, SE={1:.4f}'.format(precm,prec_se))\n",
        "print('Recall =    {0:.4f}, SE={1:.4f}'.format(recm, rec_se))\n",
        "print('f1 =        {0:.4f}, SE={1:.4f}'.format(f1m, f1_se))\n",
        "print('Accuracy =  {0:.4f}, SE={1:.4f}'.format(accm, acc_se))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X6dbcgZEnOg",
        "outputId": "52a956df-2997-4e90-d0bf-62aa56fc1b88"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision = 0.9792, SE=0.0036\n",
            "Recall =    0.9615, SE=0.0113\n",
            "f1 =        0.9700, SE=0.0067\n",
            "Accuracy =  0.9722, SE=0.0063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z2,y2 = np.unique(df1['class'].values, return_inverse=True)\n",
        "y2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0nkS9TFE9qE",
        "outputId": "2a5ceff5-7986-4c78-9af5-ce4d2cf956be"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 7, 7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = linear_model.LogisticRegression(C=1)\n",
        "logreg.fit(Xs, y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nRp7hiUE9tn",
        "outputId": "d0cb9665-a86b-4940-a44c-798905dfeef9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = logreg.predict(Xs)\n",
        "acc = np.mean(yhat == y2)\n",
        "print(\"Accuracy on training data = %f\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2Df00UJE9ws",
        "outputId": "b29e96c1-a909-46b8-9d37-951f778ba1a1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training data = 1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prec = []\n",
        "rec = []\n",
        "f1 = []\n",
        "acc = []\n",
        "\n",
        "for train, test in kf.split(Xs):            \n",
        "    # Get training and test data\n",
        "    Xtr = Xs[train,:]\n",
        "    ytr = y2[train]\n",
        "    Xts = Xs[test,:]\n",
        "    yts = y2[test]\n",
        "    \n",
        "    # Fit a model\n",
        "    logreg.fit(Xtr, ytr)\n",
        "    yhat = logreg.predict(Xts)\n",
        "    \n",
        "    # Measure performance\n",
        "    preci,reci,f1i,_= precision_recall_fscore_support(yts,yhat,average='macro') \n",
        "    prec.append(preci)\n",
        "    rec.append(reci)\n",
        "    f1.append(f1i)\n",
        "    acci = np.mean(yhat == yts)\n",
        "    acc.append(acci)\n",
        "    \n",
        "    # confusion matrix\n",
        "    C0 = confusion_matrix(yts, yhat)\n",
        "    C = C0 / C0.astype(np.float).sum(axis=1)\n",
        "    print(np.array_str(C, precision=4, suppress_small=True))\n",
        "\n",
        "# Take average values of the metrics\n",
        "precm = np.mean(prec)\n",
        "recm = np.mean(rec)\n",
        "f1m = np.mean(f1)\n",
        "accm= np.mean(acc)\n",
        "\n",
        "# Compute the standard errors\n",
        "prec_se = np.std(prec)/np.sqrt(nfold-1)\n",
        "rec_se = np.std(rec)/np.sqrt(nfold-1)\n",
        "f1_se = np.std(f1)/np.sqrt(nfold-1)\n",
        "acc_se = np.std(acc)/np.sqrt(nfold-1)\n",
        "\n",
        "print('Precision = {0:.4f}, SE={1:.4f}'.format(precm,prec_se))\n",
        "print('Recall =    {0:.4f}, SE={1:.4f}'.format(recm, rec_se))\n",
        "print('f1 =        {0:.4f}, SE={1:.4f}'.format(f1m, f1_se))\n",
        "print('Accuracy =  {0:.4f}, SE={1:.4f}'.format(accm, acc_se))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZPD_wPhE9z6",
        "outputId": "f072059c-9d2f-4e6b-ef73-84e196e0d571"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.     0.     0.     0.     0.     0.     0.     0.    ]\n",
            " [0.     0.9333 0.     0.     0.     0.125  0.     0.    ]\n",
            " [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
            " [0.     0.     0.     1.     0.     0.     0.     0.    ]\n",
            " [0.     0.     0.     0.     1.     0.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
            " [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.9524 0.     0.     0.     0.1    0.     0.     0.    ]\n",
            " [0.     1.     0.     0.     0.     0.     0.     0.    ]\n",
            " [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
            " [0.     0.     0.     1.     0.     0.     0.     0.    ]\n",
            " [0.     0.     0.     0.     1.     0.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
            " [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1.]]\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.     0.     0.     0.     0.     0.     0.     0.    ]\n",
            " [0.     1.     0.     0.     0.     0.     0.     0.    ]\n",
            " [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
            " [0.     0.     0.     0.875  0.     0.     0.     0.0833]\n",
            " [0.     0.     0.     0.     1.     0.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
            " [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
            "[[1.     0.     0.     0.     0.     0.     0.     0.    ]\n",
            " [0.     1.     0.     0.     0.     0.     0.     0.    ]\n",
            " [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
            " [0.     0.     0.     1.     0.     0.     0.     0.    ]\n",
            " [0.     0.0625 0.     0.     0.9231 0.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
            " [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.     0.     0.     0.     0.     0.     0.     0.    ]\n",
            " [0.     1.     0.     0.     0.     0.     0.     0.    ]\n",
            " [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
            " [0.0909 0.     0.     0.9444 0.     0.     0.     0.    ]\n",
            " [0.     0.     0.     0.     1.     0.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
            " [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
            "[[0.9375 0.1111 0.     0.     0.     0.     0.     0.    ]\n",
            " [0.     1.     0.     0.     0.     0.     0.     0.    ]\n",
            " [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
            " [0.0625 0.     0.     0.9286 0.     0.     0.     0.    ]\n",
            " [0.     0.     0.     0.     1.     0.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
            " [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
            "[[1.     0.     0.     0.     0.     0.     0.     0.    ]\n",
            " [0.0833 0.8462 0.     0.     0.     0.0909 0.     0.    ]\n",
            " [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
            " [0.     0.     0.     1.     0.     0.     0.     0.    ]\n",
            " [0.     0.     0.     0.     1.     0.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
            " [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
            "Precision = 0.9907, SE=0.0024\n",
            "Recall =    0.9918, SE=0.0023\n",
            "f1 =        0.9908, SE=0.0024\n",
            "Accuracy =  0.9917, SE=0.0022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = linear_model.LogisticRegression(C=1)\n",
        "logreg.fit(Xs,y2)\n",
        "\n",
        "w2 = np.squeeze(logreg.coef_)\n",
        "plt.stem(dfslope.index,w2[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "Az_lPYBQE93N",
        "outputId": "34cc327d-1ae7-4efb-9179-3698043121db"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: In Matplotlib 3.3 individual lines on a stem plot will be added as a LineCollection instead of individual lines. This significantly improves the performance of a stem plot. To remove this warning and switch to the new behaviour, set the \"use_line_collection\" keyword argument to True.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<StemContainer object of 3 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nc = 20\n",
        "c = np.logspace(-2,2,nc)\n",
        "acc = np.zeros((nc,nfold))\n",
        "\n",
        "for ifold, ind in enumerate(kf.split(Xs)):\n",
        "    \n",
        "    # Get training and test data\n",
        "    Itr,Its = ind\n",
        "    Xtr = Xs[Itr,:]\n",
        "    ytr = y[Itr]\n",
        "    Xts = Xs[Its,:]\n",
        "    yts = y[Its]\n",
        "    \n",
        "    for ia, a in enumerate(c):\n",
        "    \n",
        "        # Fit a model\n",
        "        logreg = linear_model.LogisticRegression(C=a,penalty='l1',solver='liblinear')\n",
        "        logreg.fit(Xtr, ytr)\n",
        "        yhat = logreg.predict(Xts)\n",
        "\n",
        "        # Measure accutacy\n",
        "        acc[ia,ifold] = logreg.score(Xts,yts)\n",
        "        \n",
        "# Take average values of the metrics\n",
        "accm = np.mean(acc,axis=1)\n",
        "acc_se = np.std(acc,axis=1)/np.sqrt(nfold-1)\n",
        "\n",
        "plt.errorbar(c, accm, yerr=acc_se, fmt='-')\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "tRQJ2q0oE96U",
        "outputId": "af30351f-91c2-4db2-dae3-5f928eb63de5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = (-accm).argsort()[:1]\n",
        "print(\"Optimal C = %f\" % c[i[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61Oc9liPFKpP",
        "outputId": "b569163f-e8ad-4a2d-f153-52aa782d3978"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal C = 3.359818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = linear_model.LogisticRegression(C=c[i[0]],penalty='l1',solver='liblinear')\n",
        "logreg.fit(Xs,y2)\n",
        "\n",
        "w_l1 = np.squeeze(logreg.coef_)\n",
        "plt.stem(dfslope.index,w_l1[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "l6J7J0klFMWa",
        "outputId": "49bda488-dd17-4543-999f-05d9ea67d816"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: In Matplotlib 3.3 individual lines on a stem plot will be added as a LineCollection instead of individual lines. This significantly improves the performance of a stem plot. To remove this warning and switch to the new behaviour, set the \"use_line_collection\" keyword argument to True.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<StemContainer object of 3 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ojW28QTWFzKU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}